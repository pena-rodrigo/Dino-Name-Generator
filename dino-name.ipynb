{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pena-rodrigo/Dino-Name-Generator/blob/main/dino-name.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UKVdWGDB6UG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZz4mBr7B6UG"
      },
      "source": [
        "## Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yKeHlN_3B6UH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "77OOeYeZB6UI"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vO4zal_NB6UI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.functional import F\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "zupzSx3gB6UI",
        "outputId": "76c47d62-e19b-4744-d685-72fb606659f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "dir = '/content/gdrive/MyDrive/Dino-Name-Generator-main/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.functional import F\n",
        "\n",
        "\n",
        "\n",
        "def train(model, data, num_iter, criterion, clip=0.25, lr=0.001, print_every=50,\n",
        "    sleep=False, sleep_every=None):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        model: A Pytorch's nn.Module class.\n",
        "        data: Training data, containing both x and y.\n",
        "        num_iter: Number of time to perform backward prop, (update parameters).\n",
        "        criterion: A function that takes in (out, y) and returns the loss.\n",
        "        clip: Value to clip gradients to. If None, clipping is not done.\n",
        "        lr: Learning rate.\n",
        "        print_every: Number of iterations to print averaged loss. If None, nothing\n",
        "            is printed.\n",
        "        sleep: Number of seconds to pause training.\n",
        "        sleep_every: Number of iterations to pause training. Ignored if sleep is False.\n",
        "    \n",
        "    Output:\n",
        "        model: The trained model.\n",
        "        costs: List of all the calculated loss.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    costs = []\n",
        "    running_loss = 0\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    curr_iter = 0\n",
        "    while curr_iter<num_iter:\n",
        "        for x, y in data:\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Initialise model's state and perform forward-prop\n",
        "            if isinstance(x, (list, tuple)):\n",
        "                prev_state = model.init_state(b_size=x[0].shape[0])\n",
        "            else:\n",
        "                prev_state = model.init_state(b_size=x.shape[0])\n",
        "\n",
        "            out, state = model(x, prev_state)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(out.transpose(1, 2), y)\n",
        "            costs.append(loss.item())\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate gradients and update parameters\n",
        "            loss.backward()\n",
        "            if clip:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            \n",
        "            curr_iter += 1\n",
        "            if print_every and (curr_iter%print_every)==0:\n",
        "                print(\"Iteration: {:{}}/{}, Loss: {:8.4f}\".format(\n",
        "                    curr_iter, int(math.log(num_iter, 10))+2, num_iter,\n",
        "                    running_loss/float(print_every)))\n",
        "                running_loss = 0\n",
        "                \n",
        "            if curr_iter>=num_iter:\n",
        "                break\n",
        "\n",
        "            if (sleep and sleep_every) and (curr_iter%sleep_every)==0:\n",
        "                time.sleep(sleep)\n",
        "    return model, costs"
      ],
      "metadata": {
        "id": "EW-LS9msMK-D"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.functional import F\n",
        "\n",
        "\n",
        "\n",
        "def test_dataset_batching(x, y, xlen=None):\n",
        "    \"\"\"\n",
        "        Test if x[1:] == y[:-1]. Both x and y are without padding.\n",
        "\n",
        "    Input:\n",
        "        x: Batch of x.\n",
        "        y: Batch of y.\n",
        "        xlen: True length of each sample in the batch.\n",
        "        \n",
        "    Example:\n",
        "        \n",
        "        # Assuming dataloader is the same as in the notebook dino-name_batch.ipynb\n",
        "        >>> for d in dataloader:\n",
        "        ...     test_dataset_batching(d[0][0], d[1], d[0][1])\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    for i, (xi, yi) in enumerate(zip(x, y)):\n",
        "        xi_nopad = xi[:xlen[i]] if xlen is not None else xi\n",
        "        yi_nopad = yi[:xlen[i]] if xlen is not None else yi\n",
        "        \n",
        "        if (xi_nopad[1:] == yi_nopad[:-1]).all():\n",
        "            count += 1\n",
        "    print(\"{} of {} indexes passed test.\".format(count, i+1))\n",
        "\n",
        "\n",
        "def test_model_batch_vs_nobatch(model, data, pad_ix=-100, e=1e-4):\n",
        "    \"\"\"\n",
        "        Test if model's output, state and loss is the same for batch and nobatch.\n",
        "\n",
        "    Input:\n",
        "        model: A Pytorch's nn.Module class.\n",
        "        data: ((x, xlen), y).\n",
        "        pad_ix: PAD token index. An error might be raised if it is not given.\n",
        "        e: Precision of comparision. The default value is recommended.\n",
        "        \n",
        "    Example:\n",
        "        \n",
        "        # Assuming dataloader is the same as in the notebook dino-name_batch.ipynb\n",
        "        >>> for d in dataloader:\n",
        "        ...     test_model_batch_vs_nobatch(model, d, char_to_ix[\"<PAD>\"])\n",
        "    \"\"\"\n",
        "    x, y = data\n",
        "    n_b, n_s = x[0].shape\n",
        "\n",
        "    count = {\"out\": 0, \"state\": 0, \"loss\": 0}\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=pad_ix)\n",
        "    \n",
        "    # BATCHING: Perform forward-pass with gradient calculation disabled\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        batch_out, batch_state = model(x, model.init_state(n_b))\n",
        "        batch_state = torch.cat(batch_state).transpose(0, 1)\n",
        "        batch_loss = criterion(batch_out.transpose(1, 2), y)\n",
        "        \n",
        "    # NO-BATCHING\n",
        "    for i in range(n_b):\n",
        "        xlen_i = int(x[1][i])\n",
        "\n",
        "        xi = (x[0][i][:xlen_i].unsqueeze(0), x[1][i].unsqueeze(0))\n",
        "        yi =     y[i][:xlen_i].unsqueeze(0)\n",
        "        \n",
        "        # Perform forward-pass with gradient calculation disabled\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            nobatch_out_i, nobatch_state_i = model(xi, model.init_state(1))\n",
        "            nobatch_state_i = torch.cat(nobatch_state_i).transpose(0, 1)\n",
        "            nobatch_loss_i = criterion(nobatch_out_i.transpose(1, 2), yi)\n",
        "\n",
        "        # NOTE: Each of the comparision below are calculated upto a certain precision e,\n",
        "        # due to issues arising from early rounding and floating-point precision\n",
        "\n",
        "        # check if model outputs are equal\n",
        "        if ((batch_out[i][:xlen_i] - nobatch_out_i) < e).all():\n",
        "            count[\"out\"] += 1\n",
        "\n",
        "        # check if model hidden states are equal\n",
        "        if ((batch_state[i][:xlen_i] - nobatch_state_i) < e).all():\n",
        "            count[\"state\"] += 1\n",
        "\n",
        "        # check if model loss are equal\n",
        "        if ((batch_loss[i][:xlen_i] - nobatch_loss_i) < e).all():\n",
        "            count[\"loss\"] += 1\n",
        "\n",
        "    print(\"Out: {out}/{n_b} match; State: {state}/{n_b} match; Loss: {loss}/{n_b} match.\"\n",
        "        .format(n_b=n_b, **count))\n"
      ],
      "metadata": {
        "id": "Ap9R-7fdMQAO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.functional import F\n",
        "\n",
        "\n",
        "\n",
        "def sample_next(model, x, prev_state, topk=5, uniform=True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        model: A Pytorch's nn.Module class.\n",
        "        x: The input to the model.\n",
        "        prev_state: The previous state of the model.\n",
        "        topk: The top-k output to sample from. If None, sample from the entire output.\n",
        "        uniform: Whether to sample from a uniform or a weighted distrubution of topk.\n",
        "    \n",
        "    Output:\n",
        "        sampled_ix: The sampled index.\n",
        "        state: The current state of the model.\n",
        "    \"\"\"\n",
        "    # Perform forward-prop and get the output of the last time-step\n",
        "    out, state = model(x, prev_state)\n",
        "    last_out = out[0, -1, :]\n",
        "\n",
        "    # Get the top-k indexes and their values\n",
        "    topk = topk if topk else last_out.shape[0]\n",
        "    top_logit, top_ix = torch.topk(last_out, k=topk, dim=-1)\n",
        "    \n",
        "    # Get the softmax of the topk's and sample\n",
        "    p = None if uniform else F.softmax(top_logit.detach(), dim=-1).numpy()\n",
        "    sampled_ix = np.random.choice(top_ix, p=p)\n",
        "    return sampled_ix, state\n",
        "\n",
        "\n",
        "def sample(model, seed, topk=5, uniform=True, max_seqlen=18, stop_on=None, batched=True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        model: A Pytorch's nn.Module class.\n",
        "        seed: List of indexes to intialise model with.\n",
        "        topk: The top-k output to sample from. If None, sample from the entire output.\n",
        "        uniform: Whether to sample from a uniform or a weighted distrubution of topk.\n",
        "        max_seqlen: The maximum sequence length to sample. 'seed' length is included.\n",
        "        stop_on: Index that signals the end of sequence (sampling).\n",
        "            If None, max_seqlen determines the end of sampling.\n",
        "    \n",
        "    Output:\n",
        "        sampled_ix_list: List of sampled indexes.\n",
        "    \"\"\"\n",
        "    seed = seed if isinstance(seed, (list, tuple)) else [seed]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sampled_ix_list = seed[:]\n",
        "        x = (torch.tensor([seed]), torch.tensor([len(seed)]))\n",
        "        if not batched:\n",
        "            x = torch.tensor([seed])\n",
        "        \n",
        "        prev_state = model.init_state(b_size=1)\n",
        "        for t in range(max_seqlen - len(seed)):\n",
        "            sampled_ix, prev_state = sample_next(model, x, prev_state, topk, uniform)\n",
        "\n",
        "            sampled_ix_list.append(sampled_ix)\n",
        "            x = (torch.tensor([[sampled_ix]]), torch.tensor([1]))\n",
        "            if not batched:\n",
        "                x = torch.tensor([[sampled_ix]])\n",
        "            \n",
        "            if sampled_ix==stop_on:\n",
        "                break\n",
        "    \n",
        "    model.train()\n",
        "    return sampled_ix_list\n",
        "\n",
        "\n",
        "def originality(n_samp, corpus, sampler, model, ix_list, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        n_samp: Number of samples to consider.\n",
        "        corpus: List of training examples of the format outputted by sampler.\n",
        "        sampler: A function that returns a list of sampled indexes. Must take in\n",
        "            model and a (list of) seed as it's first two arguments.\n",
        "        model: A Pytorch's nn.Module class.\n",
        "        ix_list: List of seed index, from vocab, to consider.\n",
        "\n",
        "        *arg: Arguments to pass with sampler.\n",
        "        **kwargs: Keyword arguments to pass with sampler.\n",
        "    \n",
        "    Output:\n",
        "        samples: List of samples that were considered.\n",
        "        duplicates: List of samples that are in corpus.\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "    duplicates = []\n",
        "    \n",
        "    for i in range(n_samp):\n",
        "        samp = sampler(model, random.choice(ix_list), *args, **kwargs)\n",
        "        samples.append(samp)\n",
        "\n",
        "        if samp in corpus:\n",
        "            duplicates.append(samp)\n",
        "\n",
        "    recall = 100 * len(duplicates) / n_samp\n",
        "    print(\"Duplicates: {} of {}\".format(len(duplicates), n_samp))\n",
        "    print(\"{:6.2f}% recall\".format(recall))\n",
        "    print(\"{:6.2f}% original\".format(100 - recall))\n",
        "    return samples, duplicates\n",
        "\n",
        "\n",
        "def keys_to_values(keys, _map, default):\n",
        "    \"\"\"\n",
        "        Converts values in keys to their mapped values in _map. If not found,\n",
        "        default is used instead.\n",
        "    \"\"\"\n",
        "    return [_map.get(key, default) for key in keys]\n"
      ],
      "metadata": {
        "id": "pcYHzPPxNr7s"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wD35vGd-B6UI"
      },
      "outputs": [],
      "source": [
        "# import evaluate.py\n",
        "# import training.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "iTMYh3lSB6UI"
      },
      "outputs": [],
      "source": [
        "from importlib import reload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "lMx6bqyOB6UI",
        "outputId": "4d7f0523-7f99-4261-b4fa-480dd443dd9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Dino-Name-Generator-main/clean_names.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "dir+\"clean_names.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwxPGaAgB6UI"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "stot2aggB6UI"
      },
      "outputs": [],
      "source": [
        "data_dict_re = torch.load(dir+\"clean_names.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "PyxEJYz-B6UJ"
      },
      "outputs": [],
      "source": [
        "data_in_char = data_dict_re[\"data_in_char\"]\n",
        "char_vocab = data_dict_re[\"char_vocab\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zBpaWmrB6UJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TX9QBUhB6UJ"
      },
      "source": [
        "**NOTE:** `char_vocab` contains a **PAD token** which is meant for when we want to batch our training data. We are not doing that here, so we are removing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Ovc8TnY5B6UJ"
      },
      "outputs": [],
      "source": [
        "if \"<PAD>\" in char_vocab:\n",
        "    char_vocab.remove(\"<PAD>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "JYc9I5RXB6UJ",
        "outputId": "abf17544-e803-4adc-cfbc-fc8a98011ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data length: 1545\n",
            "vocab size: 27\n"
          ]
        }
      ],
      "source": [
        "print(\"data length:\", len(data_in_char))\n",
        "print(\"vocab size:\", len(char_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WPbGwfJzB6UJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "scrolled": false,
        "id": "bFm3mCAwB6UJ",
        "outputId": "2d0ceef1-cf48-4e24-e2be-b148b74e0063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '<EOS>'], ['a', 'a', 'r', 'd', 'o', 'n', 'y', 'x', '<EOS>'], ['a', 'b', 'd', 'a', 'l', 'l', 'a', 'h', 's', 'a', 'u', 'r', 'u', 's', '<EOS>'], ['a', 'b', 'e', 'l', 'i', 's', 'a', 'u', 'r', 'u', 's', '<EOS>'], ['a', 'b', 'r', 'i', 'c', 't', 'o', 's', 'a', 'u', 'r', 'u', 's', '<EOS>']]\n"
          ]
        }
      ],
      "source": [
        "print(data_in_char[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BbV6gWGMB6UJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "orerI4y9B6UJ"
      },
      "outputs": [],
      "source": [
        "char_to_ix = {ch:i for i,ch in enumerate(char_vocab)}\n",
        "ix_to_char = {i:ch for ch,i in char_to_ix.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "t6425nFkB6UJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2Gd9MuksB6UJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qOr9z1UPB6UJ"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_as_str, _map):\n",
        "        self.data_as_int = []\n",
        "        self.max_seqlen = float(\"-inf\")\n",
        "        self.min_seqlen = float(\"inf\")\n",
        "        \n",
        "        # Convert characters to integers\n",
        "        for seq_as_str in data_as_str:\n",
        "            seq_as_int = keys_to_values(seq_as_str, _map,\n",
        "                random.choice(list(_map)))\n",
        "            \n",
        "            self.data_as_int.append(seq_as_int)\n",
        "            self.max_seqlen = max(self.max_seqlen, len(seq_as_int)-1)\n",
        "            self.min_seqlen = min(self.min_seqlen, len(seq_as_int)-1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_as_int)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        # Get data sample at index ix\n",
        "        item = self.data_as_int[ix]\n",
        "        \n",
        "        # Slice x and y from sample\n",
        "        x = item[:-1]\n",
        "        y = item[ 1:]\n",
        "        \n",
        "        return torch.tensor(x), torch.tensor(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "scrolled": true,
        "id": "QHy5cx-dB6UK"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(data_in_char, char_to_ix)\n",
        "dataloader = DataLoader(dataset, 1, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6hcv_a3aB6UK",
        "outputId": "f8870b16-50cb-4924-9006-8f791a9134ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1545\n",
            "Max sequence length: 23\n",
            "Min sequence length: 3\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset size:\", len(dataset))\n",
        "print(\"Max sequence length:\", dataset.max_seqlen)\n",
        "print(\"Min sequence length:\", dataset.min_seqlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OrQ-vcLB6UK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaJe0k_0B6UK"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "dphTLD8eB6UK"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, _map, hidden_size, emb_dim=8, n_layers=1, dropout_p=0.2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            _map: char_to_ix.\n",
        "            hidden_size: Number of features to learn.\n",
        "            emb_dim: Size of embedding vector.\n",
        "            n_layers: Number of layers.\n",
        "            dropout_p: Dropout probability.\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.vocab_size  = len(_map)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.emb_dim     = emb_dim\n",
        "        self.n_layers    = n_layers\n",
        "        self.dropout_p   = dropout_p\n",
        "        \n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.vocab_size,\n",
        "            embedding_dim =self.emb_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size =self.emb_dim,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers =self.n_layers,\n",
        "            batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features =self.hidden_size,\n",
        "            out_features=self.vocab_size)\n",
        "        \n",
        "    def forward(self, x, prev_state):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            x: x\n",
        "            prev_state: The previous state of the model.\n",
        "            \n",
        "        Output:\n",
        "            out: The output of the model.\n",
        "            state: The current state of the model.\n",
        "        \"\"\"\n",
        "        n_b, n_s = x.shape\n",
        "        \n",
        "        embed = self.embedding(x)\n",
        "        yhat, state = self.lstm(embed, prev_state)\n",
        "        \n",
        "        yhat = self.dropout(yhat)\n",
        "        out = self.fc(yhat)\n",
        "        return out, state\n",
        "    \n",
        "    def init_state(self, b_size=1):\n",
        "        return (torch.zeros(self.n_layers, b_size, self.hidden_size),\n",
        "                torch.zeros(self.n_layers, b_size, self.hidden_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "scrolled": false,
        "id": "cbYJ5LlzB6UK",
        "outputId": "a62385dd-8d3b-4809-ada5-7d6a6ef83649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(27, 8)\n",
              "  (lstm): LSTM(8, 64, batch_first=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=64, out_features=27, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "model = Model(char_to_ix, 64, 8, n_layers=1, dropout_p=0.2)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "F55U0666B6UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "3Ch5q-rgB6UL"
      },
      "outputs": [],
      "source": [
        "loss_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KjBJFH3bB6UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVEp_fpiB6UL"
      },
      "source": [
        "## Loading and Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "TbficRHVB6UL"
      },
      "outputs": [],
      "source": [
        "def load_model(path):\n",
        "    m_data = torch.load(path)\n",
        "    \n",
        "    m = Model(\n",
        "        _map       =m_data[\"_map\"],\n",
        "        hidden_size=m_data[\"hidden_size\"],\n",
        "        emb_dim    =m_data[\"emb_dim\"],\n",
        "        n_layers   =m_data[\"n_layers\"],\n",
        "        dropout_p  =m_data[\"dropout_p\"])\n",
        "    \n",
        "    m.load_state_dict(m_data[\"state_dict\"])\n",
        "    l_hist = m_data[\"loss_history\"]\n",
        "    return m, l_hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KhfkSb9B6UL"
      },
      "source": [
        "**Uncomment cell to load the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "U41QOu93B6UL"
      },
      "outputs": [],
      "source": [
        "# model, loss_history = load_model(\"./saves/model/dino-name.pt\")\n",
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UPELDSz6B6UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "a73x30EvB6UL"
      },
      "outputs": [],
      "source": [
        "def save_model(m, l_hist, _map, path=None):\n",
        "    if not path: path = dir+\"./saves/model/dino-name.pt\"\n",
        "        \n",
        "    m_data = {\n",
        "        \"_map\"        : _map,\n",
        "        \"hidden_size\" : m.hidden_size,\n",
        "        \"emb_dim\"     : m.emb_dim,\n",
        "        \"n_layers\"    : m.n_layers,\n",
        "        \"dropout_p\"   : m.dropout_p,\n",
        "        \"state_dict\"  : m.state_dict(),\n",
        "        \"loss_history\": l_hist}\n",
        "    torch.save(m_data, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "lIPwHGMeB6UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjUw8ZY0B6UL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "On0VJL9gB6UL"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "FFoFl2mZB6UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "scrolled": true,
        "id": "uduryzhMB6UL",
        "outputId": "c3d87569-c8cb-4ea4-d718-5febfe41575e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1000/5000, Loss:   1.7089\n",
            "Iteration:  2000/5000, Loss:   1.6379\n",
            "Iteration:  3000/5000, Loss:   1.6280\n",
            "Iteration:  4000/5000, Loss:   1.6102\n",
            "Iteration:  5000/5000, Loss:   1.5819\n",
            "\n",
            "==================================================\n",
            "Round:  1 of 10, Running Time:   25.32 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.5502\n",
            "Iteration:  2000/5000, Loss:   1.5665\n",
            "Iteration:  3000/5000, Loss:   1.5385\n",
            "Iteration:  4000/5000, Loss:   1.4879\n",
            "Iteration:  5000/5000, Loss:   1.5250\n",
            "\n",
            "==================================================\n",
            "Round:  2 of 10, Running Time:   49.86 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.4923\n",
            "Iteration:  2000/5000, Loss:   1.4833\n",
            "Iteration:  3000/5000, Loss:   1.4558\n",
            "Iteration:  4000/5000, Loss:   1.4529\n",
            "Iteration:  5000/5000, Loss:   1.4251\n",
            "\n",
            "==================================================\n",
            "Round:  3 of 10, Running Time:   74.24 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.4364\n",
            "Iteration:  2000/5000, Loss:   1.3890\n",
            "Iteration:  3000/5000, Loss:   1.4159\n",
            "Iteration:  4000/5000, Loss:   1.3889\n",
            "Iteration:  5000/5000, Loss:   1.3732\n",
            "\n",
            "==================================================\n",
            "Round:  4 of 10, Running Time:   99.03 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.3544\n",
            "Iteration:  2000/5000, Loss:   1.3549\n",
            "Iteration:  3000/5000, Loss:   1.3832\n",
            "Iteration:  4000/5000, Loss:   1.3245\n",
            "Iteration:  5000/5000, Loss:   1.3350\n",
            "\n",
            "==================================================\n",
            "Round:  5 of 10, Running Time:  124.65 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.3171\n",
            "Iteration:  2000/5000, Loss:   1.2994\n",
            "Iteration:  3000/5000, Loss:   1.3151\n",
            "Iteration:  4000/5000, Loss:   1.3029\n",
            "Iteration:  5000/5000, Loss:   1.2723\n",
            "\n",
            "==================================================\n",
            "Round:  6 of 10, Running Time:  166.20 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.2868\n",
            "Iteration:  2000/5000, Loss:   1.2521\n",
            "Iteration:  3000/5000, Loss:   1.2812\n",
            "Iteration:  4000/5000, Loss:   1.2450\n",
            "Iteration:  5000/5000, Loss:   1.2552\n",
            "\n",
            "==================================================\n",
            "Round:  7 of 10, Running Time:  192.50 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.2326\n",
            "Iteration:  2000/5000, Loss:   1.2228\n",
            "Iteration:  3000/5000, Loss:   1.2506\n",
            "Iteration:  4000/5000, Loss:   1.2237\n",
            "Iteration:  5000/5000, Loss:   1.1988\n",
            "\n",
            "==================================================\n",
            "Round:  8 of 10, Running Time:  217.09 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.2025\n",
            "Iteration:  2000/5000, Loss:   1.2125\n",
            "Iteration:  3000/5000, Loss:   1.1936\n",
            "Iteration:  4000/5000, Loss:   1.1889\n",
            "Iteration:  5000/5000, Loss:   1.1731\n",
            "\n",
            "==================================================\n",
            "Round:  9 of 10, Running Time:  245.50 sec\n",
            "==================================================\n",
            "\n",
            "Iteration:  1000/5000, Loss:   1.1711\n",
            "Iteration:  2000/5000, Loss:   1.1660\n",
            "Iteration:  3000/5000, Loss:   1.1723\n",
            "Iteration:  4000/5000, Loss:   1.1661\n",
            "Iteration:  5000/5000, Loss:   1.1479\n",
            "\n",
            "==================================================\n",
            "Round: 10 of 10, Running Time:  270.00 sec\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "iteration = 50000\n",
        "per_iter = 5000\n",
        "start_t = time.time()\n",
        "\n",
        "for _ti in range(iteration//per_iter):\n",
        "    model, costs = train(\n",
        "        model, dataloader, per_iter, criterion, clip=0.25, lr=1e-3, print_every=1000)\n",
        "    \n",
        "    loss_history.extend(costs)\n",
        "    save_model(model, loss_history, char_to_ix)\n",
        "    time.sleep(5)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Round: {:2} of {:2}, Running Time: {:7.2f} sec\".format(\n",
        "        _ti+1, iteration//per_iter, time.time() - start_t))\n",
        "    print(\"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "SsR6TVgQB6UL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "scrolled": true,
        "id": "RNyRJ3HUB6UM",
        "outputId": "56a49a92-ba69-41b4-af23-777c99a863d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7163f90a10>]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cum = 250\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Cross-Entropy Loss\")\n",
        "plt.plot(\n",
        "    [sum(loss_history[i:i+cum])/cum for i in range(0, len(loss_history), cum)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "scrolled": false,
        "id": "fcgayy8hB6UM",
        "outputId": "d667e65a-54d6-4f7c-c99e-670c4a289958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 55000 | Min: 0.2338 | Max: 4.8416 | Last: 0.5642 | Ave: 1.4048\n"
          ]
        }
      ],
      "source": [
        "print(\"Iter: {} | Min: {:.4f} | Max: {:.4f} | Last: {:.4f} | Ave: {:.4f}\".format(\n",
        "    len(loss_history), min(loss_history), max(loss_history), loss_history[-1],\n",
        "    sum(loss_history)/len(loss_history)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "JAKOr4qVB6UM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0xtheVPB6UM"
      },
      "source": [
        "## Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "6Z38T188B6UM"
      },
      "outputs": [],
      "source": [
        "n_samp = 100\n",
        "ix_list = list(char_to_ix.values())[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Dieq3IaWB6UM",
        "outputId": "86ef8bd1-0bcb-4e17-8a09-4d57bb4ba028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicates: 14 of 100\n",
            " 14.00% recall\n",
            " 86.00% original\n"
          ]
        }
      ],
      "source": [
        "originality = originality(\n",
        "    n_samp, dataset.data_as_int, sample, model, ix_list,\n",
        "    4, False, dataset.max_seqlen, char_to_ix[\"<EOS>\"], False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "lNOkOQIXB6UM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKeZQaN-B6UM"
      },
      "source": [
        "Initialise sampling with a **randomly chosen character**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "9uIVUl8TB6UM",
        "outputId": "61bd0e3a-02db-4489-efb2-5c185c02a213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c => chilesauris<EOS>\n",
            "t => ticompar<EOS>\n",
            "u => ulaceratops<EOS>\n",
            "l => limonasaurus<EOS>\n",
            "e => euasaurus<EOS>\n",
            "m => manospinixus<EOS>\n",
            "n => neotacrum<EOS>\n",
            "j => juangshanosaurus<EOS>\n",
            "f => futeingosaurus<EOS>\n",
            "r => rapator<EOS>\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    seed = random.choice(ix_list)\n",
        "    \n",
        "    print(ix_to_char[seed], \"=>\", \"\".join(keys_to_values(\n",
        "        sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"], False),\n",
        "        ix_to_char, \"<?>\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "JgX9CtIXB6UM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxrlhbLiB6UM"
      },
      "source": [
        "Initialise sampling with **a list of characters** instead of a single character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "scrolled": false,
        "id": "x0Ff1OtBB6UM",
        "outputId": "67ac2c03-aa88-436f-efc4-7961e6905fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python => pythongosaurus<EOS>\n",
            "python => pythonsaurus<EOS>\n",
            "python => pythongosaurus<EOS>\n",
            "python => pythongosaurus<EOS>\n",
            "python => pythongosaurus<EOS>\n",
            "python => pythongosaurus<EOS>\n",
            "python => pythongosaurus<EOS>\n",
            "python => pythonosaurus<EOS>\n",
            "python => pythongosaurus<EOS>\n",
            "python => pythongovenator<EOS>\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    word = \"python\"\n",
        "    seed = keys_to_values(list(word), char_to_ix, char_to_ix[\"<EOS>\"])\n",
        "    \n",
        "    print(word, \"=>\", \"\".join(keys_to_values(\n",
        "        sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"], False),\n",
        "        ix_to_char, \"<?>\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "YMYLsAO9B6UM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq-2N2qmB6UM"
      },
      "source": [
        "Sample the next **most likely character** instead of the next **topk most likely characters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "scrolled": false,
        "id": "BYJlKHvQB6UM",
        "outputId": "f51eaf03-4a53-491a-c20b-c9e41a94346a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<EOS> => <EOS>ingosaurus<EOS>\n",
            "----a => albisaurus<EOS>\n",
            "----b => barasaurus<EOS>\n",
            "----c => camposaurus<EOS>\n",
            "----d => dakosaurus<EOS>\n",
            "----e => europatitan<EOS>\n",
            "----f => fukuisaurus<EOS>\n",
            "----g => gandunosaurus<EOS>\n",
            "----h => hentrosaurus<EOS>\n",
            "----i => inganosaurus<EOS>\n",
            "----j => jiangxingosaurus<EOS>\n",
            "----k => kalamasaurus<EOS>\n",
            "----l => lapatoraptor<EOS>\n",
            "----m => marisaurus<EOS>\n",
            "----n => nanosaurus<EOS>\n",
            "----o => ornithomimus<EOS>\n",
            "----p => palaeosaurus<EOS>\n",
            "----q => quanhanosaurus<EOS>\n",
            "----r => rianzhousaurus<EOS>\n",
            "----s => sinosaurus<EOS>\n",
            "----t => tarchia<EOS>\n",
            "----u => utarasaurus<EOS>\n",
            "----v => velocisaurus<EOS>\n",
            "----w => wantarosaurus<EOS>\n",
            "----x => xiangshanosaurus<EOS>\n",
            "----y => yungosaurus<EOS>\n",
            "----z => zuolong<EOS>\n"
          ]
        }
      ],
      "source": [
        "for ch in char_vocab:\n",
        "    seed = char_to_ix[ch]\n",
        "    \n",
        "    print(\"{:->5}\".format(ch), \"=>\", \"\".join(keys_to_values(\n",
        "        sample(model, seed, 1, True, 30, char_to_ix[\"<EOS>\"], False),\n",
        "        ix_to_char, \"<?>\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "v-ciWJcXB6UM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJdOkAztB6UN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBVXXnKtB6UN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXrmD5NpB6UN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbRnlpa2B6UN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}